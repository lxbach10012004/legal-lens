{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3337c7f3",
   "metadata": {
    "papermill": {
     "duration": 0.006475,
     "end_time": "2024-08-10T16:00:25.502004",
     "exception": false,
     "start_time": "2024-08-10T16:00:25.495529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b3c355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:25.515332Z",
     "iopub.status.busy": "2024-08-10T16:00:25.515018Z",
     "iopub.status.idle": "2024-08-10T16:00:50.457968Z",
     "shell.execute_reply": "2024-08-10T16:00:50.457165Z"
    },
    "papermill": {
     "duration": 24.952219,
     "end_time": "2024-08-10T16:00:50.460459",
     "exception": false,
     "start_time": "2024-08-10T16:00:25.508240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\r\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (1.26.4)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (1.26.100)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (4.66.4)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2023.12.25)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2024.5.0)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch-pretrained-bert)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert) (0.6.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (2024.7.4)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (2.9.0.post0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (1.16.0)\r\n",
      "Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: botocore, pytorch-pretrained-bert\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.34.131\r\n",
      "    Uninstalling botocore-1.34.131:\r\n",
      "      Successfully uninstalled botocore-1.34.131\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.13.1 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\r\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed botocore-1.29.165 pytorch-pretrained-bert-0.6.2\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import importlib\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils import data\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "!pip install pytorch-pretrained-bert\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b5617",
   "metadata": {
    "papermill": {
     "duration": 0.007195,
     "end_time": "2024-08-10T16:00:50.475226",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.468031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# All settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37439b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.491547Z",
     "iopub.status.busy": "2024-08-10T16:00:50.490911Z",
     "iopub.status.idle": "2024-08-10T16:00:50.557073Z",
     "shell.execute_reply": "2024-08-10T16:00:50.556194Z"
    },
    "papermill": {
     "duration": 0.076636,
     "end_time": "2024-08-10T16:00:50.559104",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.482468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available? True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Files directory\n",
    "data_dir = '/kaggle/input/l-ner-data/' # Update this path with your data directory containing the train, dev, and test sets.\n",
    "output_dir = '/kaggle/working/'        # Update this path to where you want to save the model checkpoints.\n",
    "\n",
    "load_checkpoint = True                 # Whether to load a checkpoint file before model training\n",
    "do_train = True                        # Set to True to run the training procedure.\n",
    "use_local_trained_model = True         # Set to True to use the locally trained model. Set to False to load the trained model \n",
    "                                       # from HuggingFace. If do_train == False, this will be set to False.\n",
    "\n",
    "# Model settings\n",
    "language_model_name = 'lexlms/legal-longformer-base' # Replace with other language models from Hugging Face if desired.\n",
    "do_lower_case = False\n",
    "max_seq_length = 256\n",
    "\n",
    "# Training settings\n",
    "batch_size = 16\n",
    "learning_rate0 = 5e-5\n",
    "lr0_crf_fc = 8e-5\n",
    "weight_decay_finetune = 1e-5\n",
    "weight_decay_crf_fc = 5e-6\n",
    "total_train_epochs = 30\n",
    "gradient_accumulation_steps = 1\n",
    "warmup_proportion = 0.1\n",
    "\n",
    "# CUDA settings\n",
    "cuda_yes = torch.cuda.is_available()\n",
    "# cuda_yes = False\n",
    "print('Cuda is available?', cuda_yes)\n",
    "device = torch.device(\"cuda:0\" if cuda_yes else \"cpu\")\n",
    "print('Device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614c31b",
   "metadata": {
    "papermill": {
     "duration": 0.007008,
     "end_time": "2024-08-10T16:00:50.573415",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.566407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and Classes for read and organize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247cb2f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.589395Z",
     "iopub.status.busy": "2024-08-10T16:00:50.588443Z",
     "iopub.status.idle": "2024-08-10T16:00:50.594441Z",
     "shell.execute_reply": "2024-08-10T16:00:50.593714Z"
    },
    "papermill": {
     "duration": 0.015749,
     "end_time": "2024-08-10T16:00:50.596333",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.580584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for NER.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "          guid: Unique id for the example(a sentence or a pair of sentences).\n",
    "          words: list of words of sentence\n",
    "          labels_a/labels_b: (Optional) string. The label seqence of the text_a/text_b. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        # list of words of the sentence,example: [EU, rejects, German, call, to, boycott, British, lamb .]\n",
    "        self.words = words\n",
    "        # list of label sequence of the sentence,like: [B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed8df85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.612100Z",
     "iopub.status.busy": "2024-08-10T16:00:50.611826Z",
     "iopub.status.idle": "2024-08-10T16:00:50.616646Z",
     "shell.execute_reply": "2024-08-10T16:00:50.615812Z"
    },
    "papermill": {
     "duration": 0.014893,
     "end_time": "2024-08-10T16:00:50.618429",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.603536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\n",
    "    result of convert_examples_to_features(InputExample)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids,  predict_mask, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.predict_mask = predict_mask\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a60431c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.634232Z",
     "iopub.status.busy": "2024-08-10T16:00:50.633940Z",
     "iopub.status.idle": "2024-08-10T16:00:50.654297Z",
     "shell.execute_reply": "2024-08-10T16:00:50.653629Z"
    },
    "papermill": {
     "duration": 0.030402,
     "end_time": "2024-08-10T16:00:50.656099",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.625697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NERLensDataProcessor(object):\n",
    "    \"\"\"\n",
    "    Processor class for preparing and handling NER data for the LegalLensNER dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._label_types = [ 'X', '[CLS]', '[SEP]', 'O', 'B-LAW', 'I-LAW', 'B-VIOLATION', 'I-VIOLATION', 'B-VIOLATED BY', 'I-VIOLATED BY', 'B-VIOLATED ON', 'I-VIOLATED ON']\n",
    "        self._num_labels = len(self._label_types)\n",
    "        self._label_map = {label: i for i,\n",
    "                           label in enumerate(self._label_types)}\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"trainset_NER_LegalLens.csv\")))\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"devset_NER_LegalLens.csv\")))\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        # The provided Excel test file without labels needs to be handled differently\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"testset_NER_LegalLens.xlsx\"), is_test_file=True)) \n",
    "\n",
    "    def get_labels(self):\n",
    "        return self._label_types\n",
    "\n",
    "    def get_num_labels(self):\n",
    "        return self.get_num_labels\n",
    "\n",
    "    def get_label_map(self):\n",
    "        return self._label_map\n",
    "\n",
    "    def get_start_label_id(self):\n",
    "        return self._label_map['[CLS]']\n",
    "\n",
    "    def get_stop_label_id(self):\n",
    "        return self._label_map['[SEP]']\n",
    "\n",
    "    def _read_data(self, file_path, is_test_file=False):\n",
    "\n",
    "        def apply_literal_eval(x):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return x\n",
    "            \n",
    "        if is_test_file: # Read the Excel test file\n",
    "            read_df = pd.read_excel(file_path)\n",
    "            read_df['ner_tags'] = read_df['tokens'].apply(lambda x: ['X'] * len(x)) # Create dummy labels for test file\n",
    "        else: # Read CSV train and dev sets files\n",
    "            read_df = pd.read_csv(file_path)\n",
    "            \n",
    "        data = read_df.to_dict(orient='records')\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            data[i]['tokens'] = apply_literal_eval(data[i]['tokens'])\n",
    "            data[i]['ner_tags'] = apply_literal_eval(data[i]['ner_tags'])\n",
    "        return data\n",
    "\n",
    "    def _create_examples(self, data):\n",
    "        examples = []\n",
    "        for i, item in enumerate(data):\n",
    "            guid = item['id']\n",
    "            words = item['tokens']\n",
    "            labels = item['ner_tags']\n",
    "            examples.append(InputExample(\n",
    "                guid=guid, words=words, labels=labels))\n",
    "        return examples\n",
    "\n",
    "def example2feature(example, tokenizer, label_map, max_seq_length):\n",
    "    add_label = 'X'\n",
    "    tokens = ['[CLS]']\n",
    "    predict_mask = [0]\n",
    "    label_ids = [label_map['[CLS]']]\n",
    "    for i, w in enumerate(example.words):\n",
    "        # use Tokenizer to split words\n",
    "        # 1996-08-22 => 1996 - 08 - 22\n",
    "        # sheepmeat => sheep ##me ##at\n",
    "        sub_words = tokenizer.tokenize(w)\n",
    "        if not sub_words:\n",
    "            sub_words = ['[UNK]']\n",
    "        tokens.extend(sub_words)\n",
    "        for j in range(len(sub_words)):\n",
    "            if j == 0:\n",
    "                predict_mask.append(1)\n",
    "                label_ids.append(label_map[example.labels[i]])\n",
    "            else:\n",
    "                # '##xxx' -> 'X' \n",
    "                predict_mask.append(0)\n",
    "                label_ids.append(label_map[add_label])\n",
    "\n",
    "    # truncate\n",
    "    if len(tokens) > max_seq_length - 1:\n",
    "        print('Example No.{} is too long, length is {}, truncated to {}!'.format(example.guid, len(tokens), max_seq_length))\n",
    "        tokens = tokens[0:(max_seq_length - 1)]\n",
    "        predict_mask = predict_mask[0:(max_seq_length - 1)]\n",
    "        label_ids = label_ids[0:(max_seq_length - 1)]\n",
    "    tokens.append('[SEP]')\n",
    "    predict_mask.append(0)\n",
    "    label_ids.append(label_map['[SEP]'])\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segment_ids = [0] * len(input_ids)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    feat=InputFeatures(\n",
    "                # guid=example.guid,\n",
    "                # tokens=tokens,\n",
    "                input_ids=input_ids,\n",
    "                input_mask=input_mask,\n",
    "                segment_ids=segment_ids,\n",
    "                predict_mask=predict_mask,\n",
    "                label_ids=label_ids)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5cb0e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.671729Z",
     "iopub.status.busy": "2024-08-10T16:00:50.671463Z",
     "iopub.status.idle": "2024-08-10T16:00:50.680471Z",
     "shell.execute_reply": "2024-08-10T16:00:50.679658Z"
    },
    "papermill": {
     "duration": 0.018871,
     "end_time": "2024-08-10T16:00:50.682350",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.663479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NerDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for NER task, which converts examples into features that can be used by a LM.\n",
    "    \"\"\"\n",
    "    def __init__(self, examples, tokenizer, label_map, max_seq_length):\n",
    "        self.examples=examples\n",
    "        self.tokenizer=tokenizer\n",
    "        self.label_map=label_map\n",
    "        self.max_seq_length=max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat=example2feature(self.examples[idx], self.tokenizer, self.label_map, max_seq_length)\n",
    "        return feat.input_ids, feat.input_mask, feat.segment_ids, feat.predict_mask, feat.label_ids\n",
    "\n",
    "    @classmethod\n",
    "    def pad(cls, batch):\n",
    "\n",
    "        seqlen_list = [len(sample[0]) for sample in batch]\n",
    "        maxlen = np.array(seqlen_list).max()\n",
    "\n",
    "        f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: X for padding\n",
    "        input_ids_list = torch.LongTensor(f(0, maxlen))\n",
    "        input_mask_list = torch.LongTensor(f(1, maxlen))\n",
    "        segment_ids_list = torch.LongTensor(f(2, maxlen))\n",
    "        predict_mask_list = torch.BoolTensor(f(3, maxlen))\n",
    "        label_ids_list = torch.LongTensor(f(4, maxlen))\n",
    "\n",
    "        return input_ids_list, input_mask_list, segment_ids_list, predict_mask_list, label_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06ae23",
   "metadata": {
    "papermill": {
     "duration": 0.007032,
     "end_time": "2024-08-10T16:00:50.696575",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.689543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbac894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:50.713591Z",
     "iopub.status.busy": "2024-08-10T16:00:50.713063Z",
     "iopub.status.idle": "2024-08-10T16:00:54.173135Z",
     "shell.execute_reply": "2024-08-10T16:00:54.172337Z"
    },
    "papermill": {
     "duration": 3.470624,
     "end_time": "2024-08-10T16:00:54.175460",
     "exception": false,
     "start_time": "2024-08-10T16:00:50.704836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 976\n",
      "  Batch size = 16\n",
      "  Num steps = 1830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc759587d4e34fda8c55e9c9037f716b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e0efc010214c96add5f05f4726e378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28db65e379e4c4f99411fdc32a6aebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(44)\n",
    "torch.manual_seed(44)\n",
    "if cuda_yes:\n",
    "    torch.cuda.manual_seed_all(44)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "nerLensProcessor = NERLensDataProcessor()\n",
    "label_list = nerLensProcessor.get_labels()\n",
    "label_map = nerLensProcessor.get_label_map()\n",
    "train_examples = nerLensProcessor.get_train_examples(data_dir)\n",
    "dev_examples = nerLensProcessor.get_dev_examples(data_dir)\n",
    "test_examples = nerLensProcessor.get_test_examples(data_dir)\n",
    "\n",
    "total_train_steps = int(len(train_examples) / batch_size / gradient_accumulation_steps * total_train_epochs)\n",
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"% len(train_examples))\n",
    "print(\"  Batch size = %d\"% batch_size)\n",
    "print(\"  Num steps = %d\"% total_train_steps)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(language_model_name, do_lower_case=do_lower_case)\n",
    "\n",
    "train_dataset = NerDataset(train_examples,tokenizer,label_map,max_seq_length)\n",
    "dev_dataset = NerDataset(dev_examples,tokenizer,label_map,max_seq_length)\n",
    "test_dataset = NerDataset(test_examples,tokenizer,label_map,max_seq_length)\n",
    "\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)\n",
    "\n",
    "dev_dataloader = data.DataLoader(dataset=dev_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)\n",
    "\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f281ce",
   "metadata": {
    "papermill": {
     "duration": 0.007769,
     "end_time": "2024-08-10T16:00:54.192277",
     "exception": false,
     "start_time": "2024-08-10T16:00:54.184508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Definition\n",
    "\n",
    "- **Use Language Model + CRF:**\n",
    "  - **CRF (Conditional Random Field):** Used for transition and the Maximum Likelihood Estimate (MLE).\n",
    "  - **Language Model:** Responsible for the latent label, which leads to the emission of word embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d58e924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:54.209509Z",
     "iopub.status.busy": "2024-08-10T16:00:54.209035Z",
     "iopub.status.idle": "2024-08-10T16:00:54.237692Z",
     "shell.execute_reply": "2024-08-10T16:00:54.236801Z"
    },
    "papermill": {
     "duration": 0.039556,
     "end_time": "2024-08-10T16:00:54.239488",
     "exception": false,
     "start_time": "2024-08-10T16:00:54.199932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_sum_exp_1vec(vec):  # shape(1,m)\n",
    "    max_score = vec[0, np.argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "def log_sum_exp_mat(log_M, axis=-1):  # shape(n,m)\n",
    "    return torch.max(log_M, axis)[0]+torch.log(torch.exp(log_M-torch.max(log_M, axis)[0][:, None]).sum(axis))\n",
    "\n",
    "def log_sum_exp_batch(log_Tensor, axis=-1): # shape (batch_size,n,m)\n",
    "    return torch.max(log_Tensor, axis)[0]+torch.log(torch.exp(log_Tensor-torch.max(log_Tensor, axis)[0].view(log_Tensor.shape[0],-1,1)).sum(axis))\n",
    "\n",
    "\n",
    "class LM_CRF_NER(nn.Module):\n",
    "\n",
    "    def __init__(self, language_model, start_label_id, stop_label_id, num_labels, max_seq_length, batch_size, device):\n",
    "        super(LM_CRF_NER, self).__init__()\n",
    "        self.hidden_size = 768\n",
    "        self.start_label_id = start_label_id\n",
    "        self.stop_label_id = stop_label_id\n",
    "        self.num_labels = num_labels\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.device=device\n",
    "\n",
    "        # use pretrainded LM\n",
    "        self.language_model = language_model\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        # Maps the output of the LM into label space.\n",
    "        self.hidden2label = nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.num_labels, self.num_labels))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer *to* the start tag(or label),\n",
    "        # and we never transfer *from* the stop label (the model would probably learn this anyway,\n",
    "        # so this enforcement is likely unimportant)\n",
    "        self.transitions.data[start_label_id, :] = -10000\n",
    "        self.transitions.data[:, stop_label_id] = -10000\n",
    "\n",
    "        nn.init.xavier_uniform_(self.hidden2label.weight)\n",
    "        nn.init.constant_(self.hidden2label.bias, 0.0)\n",
    "\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        '''\n",
    "        This also called alpha-recursion or forward recursion, to calculate log_prob of all barX\n",
    "        '''\n",
    "\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        log_alpha = torch.Tensor(batch_size, 1, self.num_labels).fill_(-10000.).to(self.device)\n",
    "        # self.start_label has all of the score. it is log,0 is p=1\n",
    "        log_alpha[:, 0, self.start_label_id] = 0\n",
    "\n",
    "        # feats is the probability of emission, feat.shape=(1,tag_size)\n",
    "        for t in range(1, T):\n",
    "            log_alpha = (log_sum_exp_batch(self.transitions + log_alpha, axis=-1) + feats[:, t]).unsqueeze(1)\n",
    "\n",
    "        # log_prob of all barX\n",
    "        log_prob_all_barX = log_sum_exp_batch(log_alpha)\n",
    "        return log_prob_all_barX\n",
    "\n",
    "    def _get_lm_features(self, input_ids, segment_ids, input_mask):\n",
    "        '''\n",
    "        sentences -> word embeddings -> LM -> feats\n",
    "        '''\n",
    "        lm_seq_out = self.language_model(input_ids, token_type_ids=segment_ids, attention_mask=input_mask, output_hidden_states=False).last_hidden_state\n",
    "        lm_seq_out = self.dropout(lm_seq_out)\n",
    "        lm_feats = self.hidden2label(lm_seq_out)\n",
    "        return lm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, label_ids):\n",
    "        '''\n",
    "        Gives the score of a provided label sequence\n",
    "        p(X=w1:t,Zt=tag1:t)=...p(Zt=tag_t|Zt-1=tag_t-1)p(xt|Zt=tag_t)...\n",
    "        '''\n",
    "\n",
    "        # T = self.max_seq_length\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        batch_transitions = self.transitions.expand(batch_size,self.num_labels,self.num_labels)\n",
    "        batch_transitions = batch_transitions.flatten(1)\n",
    "\n",
    "        score = torch.zeros((feats.shape[0],1)).to(device)\n",
    "        # the 0th node is start_label->start_word,\bthe probability of them=1. so t begin with 1.\n",
    "        for t in range(1, T):\n",
    "            score = score + \\\n",
    "                batch_transitions.gather(-1, (label_ids[:, t]*self.num_labels+label_ids[:, t-1]).view(-1,1)) \\\n",
    "                    + feats[:, t].gather(-1, label_ids[:, t].view(-1,1)).view(-1,1)\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        '''\n",
    "        Max-Product Algorithm or viterbi algorithm, argmax(p(z_0:t|x_0:t))\n",
    "        '''\n",
    "\n",
    "        # T = self.max_seq_length\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        # batch_transitions=self.transitions.expand(batch_size,self.num_labels,self.num_labels)\n",
    "\n",
    "        log_delta = torch.Tensor(batch_size, 1, self.num_labels).fill_(-10000.).to(self.device)\n",
    "        log_delta[:, 0, self.start_label_id] = 0\n",
    "\n",
    "        # psi is for the vaule of the last latent that make P(this_latent) maximum.\n",
    "        psi = torch.zeros((batch_size, T, self.num_labels), dtype=torch.long).to(self.device)  # psi[0]=0000 useless\n",
    "        for t in range(1, T):\n",
    "            # delta[t][k]=max_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # delta[t] is the max prob of the path from  z_t-1 to z_t[k]\n",
    "            log_delta, psi[:, t] = torch.max(self.transitions + log_delta, -1)\n",
    "            # psi[t][k]=argmax_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # psi[t][k] is the path choosed from z_t-1 to z_t[k],the value is the z_state(is k) index of z_t-1\n",
    "            log_delta = (log_delta + feats[:, t]).unsqueeze(1)\n",
    "\n",
    "        # trace back\n",
    "        path = torch.zeros((batch_size, T), dtype=torch.long).to(self.device)\n",
    "\n",
    "        # max p(z1:t,all_x|theta)\n",
    "        max_logLL_allz_allx, path[:, -1] = torch.max(log_delta.squeeze(), -1)\n",
    "\n",
    "        for t in range(T-2, -1, -1):\n",
    "            # choose the state of z_t according the state choosed of z_t+1.\n",
    "            path[:, t] = psi[:, t+1].gather(-1,path[:, t+1].view(-1,1)).squeeze()\n",
    "\n",
    "        return max_logLL_allz_allx, path\n",
    "\n",
    "    def neg_log_likelihood(self, input_ids, segment_ids, input_mask, label_ids):\n",
    "        lm_feats = self._get_lm_features(input_ids, segment_ids, input_mask)\n",
    "        forward_score = self._forward_alg(lm_feats)\n",
    "        # p(X=w1:t,Zt=tag1:t)=...p(Zt=tag_t|Zt-1=tag_t-1)p(xt|Zt=tag_t)...\n",
    "        gold_score = self._score_sentence(lm_feats, label_ids)\n",
    "        # - log[ p(X=w1:t,Zt=tag1:t)/p(X=w1:t) ] = - log[ p(Zt=tag1:t|X=w1:t) ]\n",
    "        return torch.mean(forward_score - gold_score)\n",
    "\n",
    "    # this forward is just for predict, not for train\n",
    "    # dont confuse this with _forward_alg above.\n",
    "    def forward(self, input_ids, segment_ids, input_mask):\n",
    "        # Get the emission scores from the LM\n",
    "        lm_feats = self._get_lm_features(input_ids, segment_ids, input_mask)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, label_seq_ids = self._viterbi_decode(lm_feats)\n",
    "        return score, label_seq_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c36b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:00:54.256731Z",
     "iopub.status.busy": "2024-08-10T16:00:54.256445Z",
     "iopub.status.idle": "2024-08-10T16:00:59.973239Z",
     "shell.execute_reply": "2024-08-10T16:00:59.972403Z"
    },
    "papermill": {
     "duration": 5.728187,
     "end_time": "2024-08-10T16:00:59.975545",
     "exception": false,
     "start_time": "2024-08-10T16:00:54.247358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83acb3c5dd3045318b48f006823860de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e244f1c9e57e4f7e993cabac407e58be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/594M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at lexlms/legal-longformer-base and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the custom model\n",
    "start_label_id = nerLensProcessor.get_start_label_id()\n",
    "stop_label_id = nerLensProcessor.get_stop_label_id()\n",
    "\n",
    "language_model = AutoModel.from_pretrained(language_model_name)\n",
    "model = LM_CRF_NER(language_model, start_label_id, stop_label_id, len(label_list), max_seq_length, batch_size, device)\n",
    "\n",
    "#%%\n",
    "if load_checkpoint and os.path.exists(output_dir+'/ner_lm_crf_checkpoint.pt'):\n",
    "    checkpoint = torch.load(output_dir+'/ner_lm_crf_checkpoint.pt', map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch']+1\n",
    "    valid_acc_prev = checkpoint['valid_acc']\n",
    "    valid_f1_prev = checkpoint['valid_f1']\n",
    "    pretrained_dict=checkpoint['model_state']\n",
    "    net_state_dict = model.state_dict()\n",
    "    pretrained_dict_selected = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "    net_state_dict.update(pretrained_dict_selected)\n",
    "    model.load_state_dict(net_state_dict)\n",
    "    print('Loaded the pretrain NER_LM_CRF model, epoch:',checkpoint['epoch'],'valid acc:',\n",
    "            checkpoint['valid_acc'], 'valid f1:', checkpoint['valid_f1'])\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    valid_acc_prev = 0\n",
    "    valid_f1_prev = 0\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "new_param = ['transitions', 'hidden2label.weight', 'hidden2label.bias']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay) \\\n",
    "        and not any(nd in n for nd in new_param)], 'weight_decay': weight_decay_finetune},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay) \\\n",
    "        and not any(nd in n for nd in new_param)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in param_optimizer if n in ('transitions','hidden2label.weight')] \\\n",
    "        , 'lr':lr0_crf_fc, 'weight_decay': weight_decay_crf_fc},\n",
    "    {'params': [p for n, p in param_optimizer if n == 'hidden2label.bias'] \\\n",
    "        , 'lr':lr0_crf_fc, 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate0, warmup=warmup_proportion, t_total=total_train_steps)\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n",
    "\n",
    "# Revert the mapped tags\n",
    "def revert_tags(mapped_list, label_list, label_map):\n",
    "    # Reverse the label map\n",
    "    reversed_map = {v: k for k, v in label_map.items()}\n",
    "    # Convert mapped list to tag list\n",
    "    tag_list = [reversed_map[idx] for idx in mapped_list]\n",
    "    return tag_list\n",
    "\n",
    "# Convert all 'X' tags (subword tokens) to match the previous token's tag\n",
    "def process_X_tags(ner_tags):\n",
    "    processed_tags = []\n",
    "    for i, tag in enumerate(ner_tags):\n",
    "        if tag == \"X\":\n",
    "            # If the tag is \"X\", look at the previous tag\n",
    "            previous_tag = processed_tags[-1] if processed_tags else None\n",
    "            if previous_tag:\n",
    "                if previous_tag.startswith(\"B-\"):\n",
    "                    # If the previous tag is \"B-...\", convert \"X\" to \"I-...\"\n",
    "                    new_tag = \"I-\" + previous_tag[2:]\n",
    "                else:\n",
    "                    # Otherwise, copy the previous tag\n",
    "                    new_tag = previous_tag\n",
    "                processed_tags.append(new_tag)\n",
    "            else:\n",
    "                # If there's no previous tag (which shouldn't happen), keep \"X\" as is\n",
    "                processed_tags.append(\"X\")\n",
    "        else:\n",
    "            # If the tag is not \"X\", add it as is\n",
    "            processed_tags.append(tag)\n",
    "    \n",
    "    return processed_tags\n",
    "\n",
    "# Result evaluation\n",
    "def evaluate(model, predict_dataloader, batch_size, epoch_th, dataset_name, print_classification_report=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in predict_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "            _, predicted_label_seq_ids = model(input_ids, segment_ids, input_mask)\n",
    "            \n",
    "            valid_predicted = torch.masked_select(predicted_label_seq_ids, predict_mask)\n",
    "            valid_label_ids = torch.masked_select(label_ids, predict_mask)\n",
    "            \n",
    "            all_preds.extend(valid_predicted.tolist())\n",
    "            all_labels.extend(valid_label_ids.tolist())\n",
    "            \n",
    "            total += len(valid_label_ids)\n",
    "            correct += valid_predicted.eq(valid_label_ids).sum().item()\n",
    "    \n",
    "    test_acc = correct / total\n",
    "    \n",
    "    all_preds = revert_tags(all_preds, label_list, label_map)\n",
    "    all_preds = process_X_tags(all_preds)\n",
    "    all_labels = revert_tags(all_labels, label_list, label_map)\n",
    "    \n",
    "    if print_classification_report: print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Epoch:%d, Macro Acc:%.2f, Macro Precision: %.2f, Macro Recall: %.2f, Macro F1: %.2f on %s, Spend:%.3f minutes for evaluation' \\\n",
    "        % (epoch_th, 100.*test_acc, 100.*precision, 100.*recall, 100.*f1, dataset_name,(end-start)/60.0))\n",
    "    print('--------------------------------------------------------------')\n",
    "    return test_acc, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebbbe9",
   "metadata": {
    "papermill": {
     "duration": 0.008226,
     "end_time": "2024-08-10T16:00:59.992654",
     "exception": false,
     "start_time": "2024-08-10T16:00:59.984428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340f77af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:01:00.011459Z",
     "iopub.status.busy": "2024-08-10T16:01:00.010913Z",
     "iopub.status.idle": "2024-08-10T17:00:12.362151Z",
     "shell.execute_reply": "2024-08-10T17:00:12.360735Z"
    },
    "papermill": {
     "duration": 3552.363673,
     "end_time": "2024-08-10T17:00:12.364450",
     "exception": false,
     "start_time": "2024-08-10T16:01:00.000777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch:0 completed, Total training's Loss: 579078.123046875, Spend: 1.8228780627250671m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Macro Acc:86.55, Macro Precision: 23.72, Macro Recall: 18.43, Macro F1: 18.37 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:1 completed, Total training's Loss: 571984.94140625, Spend: 1.804467511177063m\n",
      "Epoch:1, Macro Acc:93.87, Macro Precision: 75.95, Macro Recall: 76.59, Macro F1: 75.90 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:2 completed, Total training's Loss: 567630.7543945312, Spend: 1.8063796997070312m\n",
      "Epoch:2, Macro Acc:95.48, Macro Precision: 83.61, Macro Recall: 86.19, Macro F1: 84.37 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:3 completed, Total training's Loss: 570136.7861328125, Spend: 1.8071044445037843m\n",
      "Epoch:3, Macro Acc:96.20, Macro Precision: 84.45, Macro Recall: 88.95, Macro F1: 86.44 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:4 completed, Total training's Loss: 569028.9765625, Spend: 1.8066576560338339m\n",
      "Epoch:4, Macro Acc:96.36, Macro Precision: 89.49, Macro Recall: 86.58, Macro F1: 87.80 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:5 completed, Total training's Loss: 566798.51953125, Spend: 1.8073209524154663m\n",
      "Epoch:5, Macro Acc:96.87, Macro Precision: 92.40, Macro Recall: 88.12, Macro F1: 90.16 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:6 completed, Total training's Loss: 567722.7080078125, Spend: 1.8053106625874837m\n",
      "Epoch:6, Macro Acc:96.09, Macro Precision: 87.19, Macro Recall: 91.66, Macro F1: 89.30 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:7 completed, Total training's Loss: 568694.2021484375, Spend: 1.8062996983528137m\n",
      "Epoch:7, Macro Acc:96.56, Macro Precision: 90.14, Macro Recall: 89.28, Macro F1: 89.59 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:8 completed, Total training's Loss: 566583.2958984375, Spend: 1.8078507900238037m\n",
      "Epoch:8, Macro Acc:97.09, Macro Precision: 90.53, Macro Recall: 90.06, Macro F1: 90.22 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:9 completed, Total training's Loss: 568271.0380859375, Spend: 1.8053907394409179m\n",
      "Epoch:9, Macro Acc:96.95, Macro Precision: 92.05, Macro Recall: 91.50, Macro F1: 91.76 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:10 completed, Total training's Loss: 566850.4638671875, Spend: 1.8049460927645364m\n",
      "Epoch:10, Macro Acc:96.82, Macro Precision: 91.20, Macro Recall: 91.39, Macro F1: 91.28 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:11 completed, Total training's Loss: 567933.9921875, Spend: 1.8095223983128865m\n",
      "Epoch:11, Macro Acc:96.71, Macro Precision: 89.37, Macro Recall: 92.21, Macro F1: 90.73 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:12 completed, Total training's Loss: 566567.7822265625, Spend: 1.8076764861742656m\n",
      "Epoch:12, Macro Acc:96.92, Macro Precision: 92.52, Macro Recall: 91.80, Macro F1: 92.13 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:13 completed, Total training's Loss: 566456.8740234375, Spend: 1.8089100440343222m\n",
      "Epoch:13, Macro Acc:96.90, Macro Precision: 92.22, Macro Recall: 91.68, Macro F1: 91.92 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:14 completed, Total training's Loss: 566354.49609375, Spend: 1.8065583149592082m\n",
      "Epoch:14, Macro Acc:97.01, Macro Precision: 92.22, Macro Recall: 91.37, Macro F1: 91.76 on Valid_set, Spend:0.161 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:15 completed, Total training's Loss: 566895.25390625, Spend: 1.8065482338269552m\n",
      "Epoch:15, Macro Acc:96.97, Macro Precision: 92.29, Macro Recall: 91.92, Macro F1: 92.08 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:16 completed, Total training's Loss: 566820.201171875, Spend: 1.810348665714264m\n",
      "Epoch:16, Macro Acc:97.00, Macro Precision: 92.00, Macro Recall: 92.01, Macro F1: 91.98 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:17 completed, Total training's Loss: 564906.4462890625, Spend: 1.8067365050315858m\n",
      "Epoch:17, Macro Acc:97.00, Macro Precision: 91.91, Macro Recall: 92.07, Macro F1: 91.97 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:18 completed, Total training's Loss: 565465.1845703125, Spend: 1.8039056221644083m\n",
      "Epoch:18, Macro Acc:96.92, Macro Precision: 92.64, Macro Recall: 92.17, Macro F1: 92.38 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:19 completed, Total training's Loss: 565426.0869140625, Spend: 1.8058981855710348m\n",
      "Epoch:19, Macro Acc:96.96, Macro Precision: 91.33, Macro Recall: 91.19, Macro F1: 91.23 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:20 completed, Total training's Loss: 567250.5927734375, Spend: 1.806254522005717m\n",
      "Epoch:20, Macro Acc:96.94, Macro Precision: 91.22, Macro Recall: 91.20, Macro F1: 91.18 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:21 completed, Total training's Loss: 566605.4091796875, Spend: 1.8055853128433228m\n",
      "Epoch:21, Macro Acc:96.97, Macro Precision: 92.14, Macro Recall: 91.34, Macro F1: 91.70 on Valid_set, Spend:0.161 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:22 completed, Total training's Loss: 565963.876953125, Spend: 1.8032023549079894m\n",
      "Epoch:22, Macro Acc:96.97, Macro Precision: 92.05, Macro Recall: 91.60, Macro F1: 91.79 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:23 completed, Total training's Loss: 565942.966796875, Spend: 1.8043585260709127m\n",
      "Epoch:23, Macro Acc:96.98, Macro Precision: 92.03, Macro Recall: 91.60, Macro F1: 91.78 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:24 completed, Total training's Loss: 564695.7236328125, Spend: 1.8065841952959696m\n",
      "Epoch:24, Macro Acc:96.94, Macro Precision: 92.10, Macro Recall: 91.47, Macro F1: 91.75 on Valid_set, Spend:0.159 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:25 completed, Total training's Loss: 565306.69140625, Spend: 1.8040966033935546m\n",
      "Epoch:25, Macro Acc:96.93, Macro Precision: 91.96, Macro Recall: 91.60, Macro F1: 91.75 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:26 completed, Total training's Loss: 566532.8125, Spend: 1.8044344107309978m\n",
      "Epoch:26, Macro Acc:96.93, Macro Precision: 91.96, Macro Recall: 91.60, Macro F1: 91.75 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:27 completed, Total training's Loss: 566537.9365234375, Spend: 1.8072977542877198m\n",
      "Epoch:27, Macro Acc:96.93, Macro Precision: 91.96, Macro Recall: 91.60, Macro F1: 91.75 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:28 completed, Total training's Loss: 566525.21484375, Spend: 1.806548281510671m\n",
      "Epoch:28, Macro Acc:96.93, Macro Precision: 91.96, Macro Recall: 91.60, Macro F1: 91.75 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:29 completed, Total training's Loss: 566536.611328125, Spend: 1.806064987182617m\n",
      "Epoch:29, Macro Acc:96.93, Macro Precision: 91.96, Macro Recall: 91.60, Macro F1: 91.75 on Valid_set, Spend:0.160 minutes for evaluation\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    \n",
    "    global_step_th = int(len(train_examples) / batch_size / gradient_accumulation_steps * start_epoch)\n",
    "\n",
    "    for epoch in range(start_epoch, total_train_epochs):\n",
    "        tr_loss = 0\n",
    "        train_start = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "\n",
    "            neg_log_likelihood = model.neg_log_likelihood(input_ids, segment_ids, input_mask, label_ids)\n",
    "\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                neg_log_likelihood = neg_log_likelihood / gradient_accumulation_steps\n",
    "\n",
    "            neg_log_likelihood.backward()\n",
    "\n",
    "            tr_loss += neg_log_likelihood.item()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                # modify learning rate with warm up \n",
    "                lr_this_step = learning_rate0 * warmup_linear(global_step_th/total_train_steps, warmup_proportion)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_this_step\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step_th += 1\n",
    "\n",
    "    #         print(\"Epoch:{}-{}/{}, Negative loglikelihood: {} \".format(epoch, step, len(train_dataloader), neg_log_likelihood.item()))\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "        print(\"Epoch:{} completed, Total training's Loss: {}, Spend: {}m\".format(epoch, tr_loss, (time.time() - train_start)/60.0))\n",
    "        valid_acc, valid_f1 = evaluate(model, dev_dataloader, batch_size, epoch, 'Valid_set')\n",
    "\n",
    "        # Save a checkpoint\n",
    "        if valid_f1 > valid_f1_prev:\n",
    "            torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'valid_acc': valid_acc,\n",
    "                'valid_f1': valid_f1, 'max_seq_length': max_seq_length, 'lower_case': do_lower_case},\n",
    "                        os.path.join(output_dir, 'ner_lm_crf_checkpoint.pt'))\n",
    "            valid_f1_prev = valid_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6603a6",
   "metadata": {
    "papermill": {
     "duration": 0.013185,
     "end_time": "2024-08-10T17:00:12.392740",
     "exception": false,
     "start_time": "2024-08-10T17:00:12.379555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8576f692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:00:12.422051Z",
     "iopub.status.busy": "2024-08-10T17:00:12.421707Z",
     "iopub.status.idle": "2024-08-10T17:00:22.945858Z",
     "shell.execute_reply": "2024-08-10T17:00:22.944682Z"
    },
    "papermill": {
     "duration": 10.541344,
     "end_time": "2024-08-10T17:00:22.948264",
     "exception": false,
     "start_time": "2024-08-10T17:00:12.406920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the local training procedure:\n",
      "Loaded the pretrained  NER_LM_CRF  model, epoch: 18 valid acc: 0.9692135460397425 valid f1: 0.9237636777976719\n",
      "Previous result of the dev set with the best epoch:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        B-LAW       0.95      0.95      0.95        82\n",
      "B-VIOLATED BY       0.97      0.94      0.96        82\n",
      "B-VIOLATED ON       0.81      0.76      0.78        82\n",
      "  B-VIOLATION       0.89      0.92      0.90       351\n",
      "        I-LAW       0.99      0.99      0.99       289\n",
      "I-VIOLATED BY       0.95      0.92      0.93       172\n",
      "I-VIOLATED ON       0.89      0.90      0.89       179\n",
      "  I-VIOLATION       0.90      0.95      0.92      4062\n",
      "            O       0.99      0.98      0.98     19712\n",
      "\n",
      "     accuracy                           0.97     25011\n",
      "    macro avg       0.93      0.92      0.92     25011\n",
      " weighted avg       0.97      0.97      0.97     25011\n",
      "\n",
      "Epoch:18, Macro Acc:96.92, Macro Precision: 92.64, Macro Recall: 92.17, Macro F1: 92.38 on Valid_set, Spend:0.167 minutes for evaluation\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9692135460397425, 0.9237636777976719)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "if do_train == False: use_local_trained_model = False # If no training occurs, there would be no local trained model\n",
    "\n",
    "if use_local_trained_model: # Reload the local model that've just been trained\n",
    "    checkpoint = torch.load(output_dir+'/ner_lm_crf_checkpoint.pt', map_location='cpu')\n",
    "    print(\"From the local training procedure:\")\n",
    "  # OR\n",
    "else: # Load the trained model from huggingface \n",
    "    repo_id = \"lxbach10012004/ner-lm-crf\"\n",
    "    filename = \"ner_lm_crf_checkpoint.pt\"\n",
    "    api_key = \"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\"\n",
    "\n",
    "    # Download the file\n",
    "    checkpoint_path = hf_hub_download(repo_id=repo_id, filename=filename, use_auth_token=api_key)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    print(\"From HuggingFace:\")\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "valid_acc_prev = checkpoint['valid_acc']\n",
    "valid_f1_prev = checkpoint['valid_f1']\n",
    "pretrained_dict=checkpoint['model_state']\n",
    "net_state_dict = model.state_dict()\n",
    "pretrained_dict_selected = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "net_state_dict.update(pretrained_dict_selected)\n",
    "model.load_state_dict(net_state_dict)\n",
    "print('Loaded the pretrained  NER_LM_CRF  model, epoch:',checkpoint['epoch'],'valid acc:',\n",
    "      checkpoint['valid_acc'], 'valid f1:', checkpoint['valid_f1'])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Previous result of the dev set with the best epoch:\")\n",
    "evaluate(model, dev_dataloader, batch_size, epoch, 'Valid_set', print_classification_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399cd6f",
   "metadata": {
    "papermill": {
     "duration": 0.013974,
     "end_time": "2024-08-10T17:00:22.976200",
     "exception": false,
     "start_time": "2024-08-10T17:00:22.962226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d082cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:00:23.005457Z",
     "iopub.status.busy": "2024-08-10T17:00:23.004545Z",
     "iopub.status.idle": "2024-08-10T17:00:33.892433Z",
     "shell.execute_reply": "2024-08-10T17:00:33.891178Z"
    },
    "papermill": {
     "duration": 10.904605,
     "end_time": "2024-08-10T17:00:33.894524",
     "exception": false,
     "start_time": "2024-08-10T17:00:22.989919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_NERLens.csv\n"
     ]
    }
   ],
   "source": [
    "# Test_set prediction using the best epoch of NER_LM_CRF model\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    demon_dataloader = data.DataLoader(dataset=test_dataset, batch_size=10, shuffle=False, num_workers=4, collate_fn=NerDataset.pad)\n",
    "    for batch in demon_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "        _, predicted_label_seq_ids = model(input_ids, segment_ids, input_mask)\n",
    "        valid_predicted = torch.masked_select(predicted_label_seq_ids, predict_mask)\n",
    "        \n",
    "        for i in range(len(input_ids)):\n",
    "            new_ids = predicted_label_seq_ids[i].cpu().numpy()[predict_mask[i].cpu().numpy() == 1]\n",
    "            predicted_tags = list(map(lambda i: label_list[i], new_ids))\n",
    "            predictions.append(predicted_tags)\n",
    "            \n",
    "# Post process the 'X' tags and add predicted tags to the test dataset records\n",
    "for i, example in enumerate(test_examples):\n",
    "    prediction = process_X_tags(predictions[i])\n",
    "    example.predicted_tags = prediction\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = 'predictions_NERLens.csv'\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['id', 'tokens', 'ner_tags'])\n",
    "    writer.writeheader()\n",
    "    for example in test_examples:\n",
    "        row = {\n",
    "            'id': example.__dict__['guid'],\n",
    "            'tokens': example.__dict__['words'],\n",
    "            'ner_tags': example.__dict__['predicted_tags']\n",
    "        }\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5396019,
     "sourceId": 9141604,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5520067,
     "sourceId": 9145205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3613.785365,
   "end_time": "2024-08-10T17:00:36.418076",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-10T16:00:22.632711",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04ad1bd8eaf94e0a95e0e66183eb7acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0dc8d45c3bd74366a50f68aca4b5080f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17c9b3de7077441da085b415cb64e083": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b7637a82806499093d5616fdef438c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfb0d07576ab4d8f8f728c6c0c5271a9",
       "placeholder": "​",
       "style": "IPY_MODEL_4fd0b766b735401c8a517dd9d8069988",
       "value": " 1.00k/1.00k [00:00&lt;00:00, 92.3kB/s]"
      }
     },
     "1cd1b1d25726479ca787fbe71321b4bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4fa710047b44fa7b2066d3b746f6570",
       "placeholder": "​",
       "style": "IPY_MODEL_04ad1bd8eaf94e0a95e0e66183eb7acc",
       "value": " 167/167 [00:00&lt;00:00, 15.0kB/s]"
      }
     },
     "25859e44200841c0a538990574d37c3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "303ed301f9964fd6b646ffd76cdc2902": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "30b40b1bbb9d4c0892d6a739213c899f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "357e875c428b4011aed26bfcaca886d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b2024e6c5a34f039262e13170d6b2c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ec760e3e3e64879953943620dc281ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fd0b766b735401c8a517dd9d8069988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "51c9584958554a70b4548ff6cab41e5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_596dd805cd6b4c9a9db410fd551ea945",
       "placeholder": "​",
       "style": "IPY_MODEL_6eb1174e10224923ad3b644877ae4176",
       "value": " 594M/594M [00:03&lt;00:00, 137MB/s]"
      }
     },
     "58eb0134f5914d49af3486f9207f3290": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "596dd805cd6b4c9a9db410fd551ea945": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f61cf1d6545493c87c807c6a3fd0875": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6eb1174e10224923ad3b644877ae4176": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f95c1593f7c415eb7a7244e5ad0c198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78890e668e8640cf902ed2e32953cef3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "793af7c6ffef4f8992b892d2462beaf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7af7585d5fbc4a73b8058f957b499860": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6f95c1593f7c415eb7a7244e5ad0c198",
       "max": 1004.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad9f6165cef648d3bd42048bc7bb1fd7",
       "value": 1004.0
      }
     },
     "7e27a44f082a4c87b0adc5a61f58ee49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83acb3c5dd3045318b48f006823860de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dcdda104d9314904bfcf3bad7cd1400b",
        "IPY_MODEL_7af7585d5fbc4a73b8058f957b499860",
        "IPY_MODEL_1b7637a82806499093d5616fdef438c8"
       ],
       "layout": "IPY_MODEL_7e27a44f082a4c87b0adc5a61f58ee49"
      }
     },
     "85794cc9faba474fae310d394bb535e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88c8960767a045ab89dac244b7eb5d22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c74f2237223430a836113e0c9d315e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9189a7d6a6ab4e4c8ba96fc2f4895db6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "976ab04b44dd4907a542e52ff07ffd87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bbc7ac3e79a4e998c668a74787bb41b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78890e668e8640cf902ed2e32953cef3",
       "max": 377.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b2024e6c5a34f039262e13170d6b2c2",
       "value": 377.0
      }
     },
     "9fc608b2ce494a2ba11bdd0e7bc1e0ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad9f6165cef648d3bd42048bc7bb1fd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b52886d00438407083bd8db42679c544": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_357e875c428b4011aed26bfcaca886d7",
       "placeholder": "​",
       "style": "IPY_MODEL_85794cc9faba474fae310d394bb535e8",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "b732e42196594e69920dc8c8a6e3f7bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f0a8385b31274176a39a2b2e59737e2e",
       "max": 594100120.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_793af7c6ffef4f8992b892d2462beaf3",
       "value": 594100120.0
      }
     },
     "bae76951a0544bf2bc556c244af5e039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9fc608b2ce494a2ba11bdd0e7bc1e0ea",
       "placeholder": "​",
       "style": "IPY_MODEL_0dc8d45c3bd74366a50f68aca4b5080f",
       "value": "tokenizer.json: 100%"
      }
     },
     "bf6d11333bae4ad6a97f446587aae915": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf7d00930e594c37acdb4cc4a73c497d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3ec760e3e3e64879953943620dc281ba",
       "max": 2163181.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e91ab7160ffc473cb506691de16c94f2",
       "value": 2163181.0
      }
     },
     "c391c17d6dfb4600a72f02d3ce010aea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bf6d11333bae4ad6a97f446587aae915",
       "max": 167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d96532f1ef6949acb24a2dd936b39d9f",
       "value": 167.0
      }
     },
     "ca03692f7edd40bb81660b0709839bad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f61cf1d6545493c87c807c6a3fd0875",
       "placeholder": "​",
       "style": "IPY_MODEL_303ed301f9964fd6b646ffd76cdc2902",
       "value": "model.safetensors: 100%"
      }
     },
     "cdf56356d4e341f1bedc29e62c59959e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed252cca628540afa964a9858db4480f",
       "placeholder": "​",
       "style": "IPY_MODEL_30b40b1bbb9d4c0892d6a739213c899f",
       "value": " 377/377 [00:00&lt;00:00, 25.7kB/s]"
      }
     },
     "ce97ab396f6a4d3b937cb52ef90ef157": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0e0efc010214c96add5f05f4726e378": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bae76951a0544bf2bc556c244af5e039",
        "IPY_MODEL_bf7d00930e594c37acdb4cc4a73c497d",
        "IPY_MODEL_ffbf9b9f099d42a0bf5fa1170f0335b7"
       ],
       "layout": "IPY_MODEL_88c8960767a045ab89dac244b7eb5d22"
      }
     },
     "d808bcded3f640cabf9aa70ab7dcfa0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d96532f1ef6949acb24a2dd936b39d9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dc759587d4e34fda8c55e9c9037f716b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eb5bd4ce839e4a8180a15d7803ea2193",
        "IPY_MODEL_9bbc7ac3e79a4e998c668a74787bb41b",
        "IPY_MODEL_cdf56356d4e341f1bedc29e62c59959e"
       ],
       "layout": "IPY_MODEL_976ab04b44dd4907a542e52ff07ffd87"
      }
     },
     "dcdda104d9314904bfcf3bad7cd1400b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25859e44200841c0a538990574d37c3d",
       "placeholder": "​",
       "style": "IPY_MODEL_9189a7d6a6ab4e4c8ba96fc2f4895db6",
       "value": "config.json: 100%"
      }
     },
     "df5babe87cb441ae9de6b24b7363433f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfb0d07576ab4d8f8f728c6c0c5271a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e244f1c9e57e4f7e993cabac407e58be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ca03692f7edd40bb81660b0709839bad",
        "IPY_MODEL_b732e42196594e69920dc8c8a6e3f7bf",
        "IPY_MODEL_51c9584958554a70b4548ff6cab41e5e"
       ],
       "layout": "IPY_MODEL_ce97ab396f6a4d3b937cb52ef90ef157"
      }
     },
     "e4fa710047b44fa7b2066d3b746f6570": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e91ab7160ffc473cb506691de16c94f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eb5bd4ce839e4a8180a15d7803ea2193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d808bcded3f640cabf9aa70ab7dcfa0d",
       "placeholder": "​",
       "style": "IPY_MODEL_58eb0134f5914d49af3486f9207f3290",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "ed252cca628540afa964a9858db4480f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0a8385b31274176a39a2b2e59737e2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f28db65e379e4c4f99411fdc32a6aebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b52886d00438407083bd8db42679c544",
        "IPY_MODEL_c391c17d6dfb4600a72f02d3ce010aea",
        "IPY_MODEL_1cd1b1d25726479ca787fbe71321b4bd"
       ],
       "layout": "IPY_MODEL_df5babe87cb441ae9de6b24b7363433f"
      }
     },
     "ffbf9b9f099d42a0bf5fa1170f0335b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17c9b3de7077441da085b415cb64e083",
       "placeholder": "​",
       "style": "IPY_MODEL_8c74f2237223430a836113e0c9d315e9",
       "value": " 2.16M/2.16M [00:00&lt;00:00, 6.68MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
