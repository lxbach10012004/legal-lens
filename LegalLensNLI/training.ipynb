{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-13T04:48:22.812807Z","iopub.status.busy":"2024-08-13T04:48:22.812477Z","iopub.status.idle":"2024-08-13T04:48:23.561515Z","shell.execute_reply":"2024-08-13T04:48:23.560405Z","shell.execute_reply.started":"2024-08-13T04:48:22.812777Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:23.567692Z","iopub.status.busy":"2024-08-13T04:48:23.567308Z","iopub.status.idle":"2024-08-13T04:48:28.987166Z","shell.execute_reply":"2024-08-13T04:48:28.986386Z","shell.execute_reply.started":"2024-08-13T04:48:23.567654Z"},"trusted":true},"outputs":[],"source":["import traceback\n","import torch\n","import transformers\n","from datasets import load_dataset\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import LambdaLR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:28.988731Z","iopub.status.busy":"2024-08-13T04:48:28.988224Z","iopub.status.idle":"2024-08-13T04:48:29.023030Z","shell.execute_reply":"2024-08-13T04:48:29.022309Z","shell.execute_reply.started":"2024-08-13T04:48:28.988703Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('full_train.csv')\n","test_df = pd.read_csv('test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:29.025560Z","iopub.status.busy":"2024-08-13T04:48:29.025195Z","iopub.status.idle":"2024-08-13T04:48:36.063347Z","shell.execute_reply":"2024-08-13T04:48:36.062314Z","shell.execute_reply.started":"2024-08-13T04:48:29.025535Z"},"trusted":true},"outputs":[],"source":["# Load model directly\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:36.065078Z","iopub.status.busy":"2024-08-13T04:48:36.064698Z","iopub.status.idle":"2024-08-13T04:48:36.075511Z","shell.execute_reply":"2024-08-13T04:48:36.074528Z","shell.execute_reply.started":"2024-08-13T04:48:36.065044Z"},"trusted":true},"outputs":[],"source":["class LegalLensDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len = 512, num_labels = 3):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.encoded_label = {'Contradict': 0, 'Entailed':1, 'Neutral': 2}\n","        if num_labels == 2:\n","            self.encoded_label['Neutral'] = 0\n","    def __getitem__(self, idx):\n","        try:\n","            item = self.data.iloc[idx]\n","            pre = item.premise\n","            hypo = item.hypothesis\n","            label = self.encoded_label[item.label]\n","            encoded_input = self.tokenizer(pre, hypo, padding = 'max_length',\n","                                truncation = True, max_length = self.max_len, \n","                                           return_tensors = 'pt')\n","            return {'input_ids' : encoded_input['input_ids'].squeeze(),\n","                  'token_type_ids' : encoded_input['token_type_ids'].squeeze(),\n","                  'attention_mask' : encoded_input['attention_mask'].squeeze(),\n","                  'labels' : torch.tensor(label, dtype=torch.long)}\n","        except:\n","            traceback.print_exc()\n","            return None\n","    def __len__(self):\n","        return len(self.data)\n","    \n","train = LegalLensDataset(train_df, tokenizer, num_labels = 3)\n","test = LegalLensDataset(test_df, tokenizer, num_labels = 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:36.077125Z","iopub.status.busy":"2024-08-13T04:48:36.076794Z","iopub.status.idle":"2024-08-13T04:48:36.090322Z","shell.execute_reply":"2024-08-13T04:48:36.089401Z","shell.execute_reply.started":"2024-08-13T04:48:36.077094Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = logits.argmax(axis=-1)\n","    f1_macro = f1_score(labels, predictions, average = 'macro')\n","    precision = precision_score(labels, predictions, average = 'macro')\n","    recall = recall_score(labels, predictions, average = 'macro')\n","    return {'f1_macro': f1_macro, 'precision': precision, 'recall': recall}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:36.091737Z","iopub.status.busy":"2024-08-13T04:48:36.091404Z","iopub.status.idle":"2024-08-13T04:48:36.703119Z","shell.execute_reply":"2024-08-13T04:48:36.702114Z","shell.execute_reply.started":"2024-08-13T04:48:36.091714Z"},"trusted":true},"outputs":[],"source":["from transformers import get_cosine_schedule_with_warmup\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","num_training_steps = 15 * len(train)\n","num_warmup_steps = int(0.05 * num_training_steps)\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T04:48:36.704855Z","iopub.status.busy":"2024-08-13T04:48:36.704394Z","iopub.status.idle":"2024-08-13T05:30:03.820340Z","shell.execute_reply":"2024-08-13T05:30:03.819214Z","shell.execute_reply.started":"2024-08-13T04:48:36.704828Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',               \n","    evaluation_strategy=\"epoch\",    \n","    save_strategy=\"epoch\",   \n","    learning_rate=5e-06,       \n","    per_device_train_batch_size=1,   \n","    gradient_accumulation_steps=2,\n","    per_device_eval_batch_size=1,         \n","    num_train_epochs=8,                   \n","    warmup_ratio=0.06,         \n","    weight_decay=0.01,                  \n","    load_best_model_at_end=True,           \n","    metric_for_best_model='f1_macro',      \n","    greater_is_better=True,\n","    logging_strategy='epoch',\n","    save_total_limit=1\n",")\n","\n","trainer = Trainer(\n","    model=model,                           \n","    args=training_args,                   \n","    train_dataset=train,           \n","    eval_dataset=test,             \n","    compute_metrics=compute_metrics\n","\n",")\n","\n","# Train the model\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T05:30:03.823450Z","iopub.status.busy":"2024-08-13T05:30:03.821679Z","iopub.status.idle":"2024-08-13T05:30:26.813252Z","shell.execute_reply":"2024-08-13T05:30:26.812091Z","shell.execute_reply.started":"2024-08-13T05:30:03.823422Z"},"trusted":true},"outputs":[],"source":["results = trainer.evaluate()\n","print(results)\n","\n","trainer.save_model('./best_deberta_large')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5468974,"sourceId":9067536,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
